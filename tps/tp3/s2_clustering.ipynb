{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering sur CAMille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ing Armel\n",
      "[nltk_data]     Fopa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import re\n",
    "import nltk\n",
    "import collections\n",
    "import os\n",
    "import string\n",
    "import sys\n",
    "from pprint import pprint\n",
    "from scipy.spatial.distance import cosine\n",
    "from nltk import word_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from wordcloud import WordCloud\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix de la d√©cennie et exploration du fichiers CAMille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verification du dossiers CAMille"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dossier existant? True\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../../data/txt\")\n",
    "\n",
    "print(\"Dossier existant?\", data_dir.exists())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recencons les fichiers par decennie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Nombre de fichiers par d√©cennie :\n",
      "\n",
      "1830s : 1 fichiers\n",
      "   - KB_JB555_1836-02-08_01-00002.txt\n",
      "\n",
      "1840s : 1 fichiers\n",
      "   - KB_JB449_1846-05-30_01-00002.txt\n",
      "\n",
      "1850s : 3 fichiers\n",
      "   - KB_JB494_1853-10-30_01-0002.txt\n",
      "   - KB_JB567_1857-02-02_01-00003.txt\n",
      "   - KB_JB572_1850-03-15_01-00003.txt\n",
      "\n",
      "1860s : 2 fichiers\n",
      "   - KB_JB638_1860-05-21_01-00002.txt\n",
      "   - KB_JB92_1860-02-09_01-00003.txt\n",
      "\n",
      "1870s : 1 fichiers\n",
      "   - KB_JB92_1873-02-06_01-00002.txt\n",
      "\n",
      "1880s : 4 fichiers\n",
      "   - KB_JB258_1884-09-03_01-0003.txt\n",
      "   - KB_JB837_1886-12-28_01-00002.txt\n",
      "   - KB_JB838_1887-12-28_01-00003.txt\n",
      "   - KB_JB92_1885-09-29_01-00002.txt\n",
      "\n",
      "1890s : 7 fichiers\n",
      "   - KB_JB230_1892-08-07_01-0003.txt\n",
      "   - KB_JB258_1894-12-09_01-0003.txt\n",
      "   - KB_JB421_1899-05-15_01-00003.txt\n",
      "   - KB_JB555_1899-01-19_01-00003.txt\n",
      "   - KB_JB567_1892-01-03_01-00005.txt\n",
      "   - KB_JB685_1894-05-14_01-0003.txt\n",
      "   - KB_JB729_1895-10-08_01-00003.txt\n",
      "\n",
      "1900s : 4 fichiers\n",
      "   - KB_JB230_1903-10-16_01-0002.txt\n",
      "   - KB_JB258_1906-01-09_01-0002.txt\n",
      "   - KB_JB638_1902-12-20_01-00002.txt\n",
      "   - KB_JB685_1903-01-18_01-0002.txt\n",
      "\n",
      "1910s : 6 fichiers\n",
      "   - KB_JB230_1913-07-05_01-0001.txt\n",
      "   - KB_JB449_1912-01-04_01-00003.txt\n",
      "   - KB_JB685_1913-06-07_01-0006.txt\n",
      "   - KB_JB773_1918-11-30_01-00002.txt\n",
      "   - KB_JB835_1911-04-24_01-00004.txt\n",
      "   - KB_JB838_1911-08-03_01-00006.txt\n",
      "\n",
      "1920s : 7 fichiers\n",
      "   - KB_JB421_1926-10-29_01-00002.txt\n",
      "   - KB_JB427_1920-01-10_01-00004.txt\n",
      "   - KB_JB494_1922-09-28_01-0005.txt\n",
      "   - KB_JB567_1924-08-30_01-00003.txt\n",
      "   - KB_JB572_1927-07-20_01-00005.txt\n",
      "   - KB_JB729_1927-11-15_01-00004.txt\n",
      "   - KB_JB837_1925-01-01_01-00003.txt\n",
      "\n",
      "1930s : 5 fichiers\n",
      "   - KB_JB427_1933-01-04_01-00003.txt\n",
      "   - KB_JB494_1939-12-08_01-0004.txt\n",
      "   - KB_JB729_1939-10-31_01-00006.txt\n",
      "   - KB_JB773_1933-10-07_01-00007.txt\n",
      "   - KB_JB835_1930-04-08_01-00006.txt\n",
      "\n",
      "1940s : 6 fichiers\n",
      "   - KB_JB427_1949-07-18_01-00008.txt\n",
      "   - KB_JB449_1947-08-29_01-00003.txt\n",
      "   - KB_JB555_1940-03-01_01-00004.txt\n",
      "   - KB_JB638_1946-07-18_01-00003.txt\n",
      "   - KB_JB835_1949-09-18_01-00004.txt\n",
      "   - KB_JB838_1943-09-04_01-00002.txt\n",
      "\n",
      "1950s : 4 fichiers\n",
      "   - KB_JB421_1950-04-15_01-00004.txt\n",
      "   - KB_JB572_1950-06-07_01-00004.txt\n",
      "   - KB_JB773_1950-07-22_01-00010.txt\n",
      "   - KB_JB837_1950-12-01_01-00007.txt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "data_dir = Path(\"../../data/txt\")\n",
    "all_txt = sorted(data_dir.glob(\"*.txt\"))\n",
    "\n",
    "# Dictionnaire d√©cennie : liste de fichiers\n",
    "decades = defaultdict(list)\n",
    "\n",
    "pattern = re.compile(r\"(\\d{4})\")\n",
    "\n",
    "for path in all_txt:\n",
    "    match = pattern.search(path.name)\n",
    "    if match:\n",
    "        year = int(match.group(1))\n",
    "        decade = (year // 10) * 10\n",
    "        decades[decade].append(path.name)\n",
    "\n",
    "# Afficher un r√©sum√© clair\n",
    "print(\"Nombre de fichiers par d√©cennie :\\n\")\n",
    "for dec in sorted(decades.keys()):\n",
    "    print(f\"{dec}s : {len(decades[dec])} fichiers\")\n",
    "    for name in decades[dec]:\n",
    "        print(\"   -\", name)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix de la d√©cennie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decennie s√©lectionn√© : 1920s\n",
      "Nombre de fichiers : 7\n",
      " - KB_JB421_1926-10-29_01-00002.txt\n",
      " - KB_JB427_1920-01-10_01-00004.txt\n",
      " - KB_JB494_1922-09-28_01-0005.txt\n",
      " - KB_JB567_1924-08-30_01-00003.txt\n",
      " - KB_JB572_1927-07-20_01-00005.txt\n",
      " - KB_JB729_1927-11-15_01-00004.txt\n",
      " - KB_JB837_1925-01-01_01-00003.txt\n"
     ]
    }
   ],
   "source": [
    "DECADE = 1920\n",
    "files_decade = decades[DECADE]\n",
    "\n",
    "print(f\"Decennie s√©lectionn√© : {DECADE}s\")\n",
    "print(f\"Nombre de fichiers : {len(files_decade)}\")\n",
    "\n",
    "for name in files_decade:\n",
    "    print(\" -\", name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Liste et Filtrage des fichiers de la d√©cennie choisie (1950-1959)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de fichiers pour la d√©cennie '194' : 6 \n",
      " - KB_JB427_1949-07-18_01-00008.txt\n",
      " - KB_JB449_1947-08-29_01-00003.txt\n",
      " - KB_JB555_1940-03-01_01-00004.txt\n",
      " - KB_JB638_1946-07-18_01-00003.txt\n",
      " - KB_JB835_1949-09-18_01-00004.txt\n",
      " - KB_JB838_1943-09-04_01-00002.txt\n"
     ]
    }
   ],
   "source": [
    "# Liste des fichiers .txt\n",
    "all_txt = sorted(data_dir.glob(\"*.txt\"))\n",
    "\n",
    "# Filtrage pour la d√©cennie choisie\n",
    "files_decade = [p for p in all_txt if DECADE in p.name]\n",
    "\n",
    "print(f\"Nombre de fichiers pour la d√©cennie '{DECADE}' : {len(files_decade)} \")\n",
    "for p in files_decade[:10]:\n",
    "    print(\" -\", p.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download(\"punkt_tab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/txt/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choisir une d√©cennie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DECADE = '1950'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Charger tous les  fichiers de la d√©cennie et en cr√©er une liste de textes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = [f for f in sorted(os.listdir(data_path)) if f\"_{DECADE[:-1]}\" in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de fichiers\n",
    "files[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [open(data_path + f, \"r\", encoding=\"utf-8\").read() for f in files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple de textes\n",
    "texts[0][:400]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectoriser les documents √† l'aide de TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cr√©ation d'une fonction de pr√©-traitement\n",
    "def preprocessing(text, stem=True):\n",
    "    \"\"\" Tokenize text and remove punctuation \"\"\"\n",
    "    text = text.translate(string.punctuation)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancier le mod√®le TF-IDF avec ses arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    tokenizer=preprocessing,\n",
    "    stop_words=stopwords.words('french'),\n",
    "    max_df=0.5,\n",
    "    min_df=0.1,\n",
    "    lowercase=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire la matrice de vecteurs √† l'aide de la fonction `fit_transform`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectors = vectorizer.fit_transform(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# D√©tail de la matrice\n",
    "tfidf_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imprimer le vecteur tf-IDF du premier document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series(\n",
    "    tfidf_vectors[0].toarray()[0],\n",
    "    index=vectorizer.get_feature_names_out()\n",
    "    ).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprendre les vecteurs et leurs \"distances\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine([1, 2, 3], [1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine([1, 2, 3], [1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine([1, 2, 3], [2, 2, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests sur nos documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_array = tfidf_vectors.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecteur du document 0\n",
    "tfidf_array[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vecteur du document 1\n",
    "tfidf_array[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine(tfidf_array[0], tfidf_array[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer un algorithme de clustering sur les vecteurs TF-IDF des documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour en savoir plus sur le KMeans clustering :\n",
    "- https://medium.com/dataseries/k-means-clustering-explained-visually-in-5-minutes-b900cc69d175"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D√©finir un nombre de clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_CLUSTERS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancier le mod√®le K-Means et ses arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km_model = KMeans(n_clusters=N_CLUSTERS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer le clustering √† l'aide de la fonction `fit_predict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters = km_model.fit_predict(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering = collections.defaultdict(list)\n",
    "\n",
    "for idx, label in enumerate(clusters):\n",
    "    clustering[label].append(files[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dict(clustering))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser les clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©duire les vecteurs √† 2 dimensions √† l'aide de l'algorithme PCA\n",
    "Cette √©tape est n√©cessaire afin de visualiser les documents dans un espace 2D\n",
    "\n",
    "https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "reduced_vectors = pca.fit_transform(tfidf_vectors.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_vectors[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G√©n√©rer le plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = reduced_vectors[:, 0]\n",
    "y_axis = reduced_vectors[:, 1]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "scatter = plt.scatter(x_axis, y_axis, s=100, c=clusters)\n",
    "\n",
    "# Ajouter les centro√Ødes\n",
    "centroids = pca.transform(km_model.cluster_centers_)\n",
    "plt.scatter(centroids[:, 0], centroids[:, 1],  marker = \"x\", s=100, linewidths = 2, color='black')\n",
    "\n",
    "# Ajouter la l√©gende\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=set(clusters), title=\"Clusters\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJET_TAC_1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
