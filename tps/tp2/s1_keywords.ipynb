{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation du corpus CAMille"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recencement des années disponibles dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total fichiers txt: 51\n",
      "Années détectées: 37\n",
      "1950: 4\n",
      "1892: 2\n",
      "1903: 2\n",
      "1913: 2\n",
      "1894: 2\n",
      "1899: 2\n",
      "1933: 2\n",
      "1949: 2\n",
      "1939: 2\n",
      "1927: 2\n",
      "1860: 2\n",
      "1911: 2\n",
      "1884: 1\n",
      "1906: 1\n",
      "1926: 1\n",
      "1920: 1\n",
      "1846: 1\n",
      "1912: 1\n",
      "1947: 1\n",
      "1853: 1\n",
      "1922: 1\n",
      "1836: 1\n",
      "1940: 1\n",
      "1857: 1\n",
      "1924: 1\n",
      "1850: 1\n",
      "1902: 1\n",
      "1946: 1\n",
      "1895: 1\n",
      "1918: 1\n",
      "1930: 1\n",
      "1886: 1\n",
      "1925: 1\n",
      "1887: 1\n",
      "1943: 1\n",
      "1873: 1\n",
      "1885: 1\n"
     ]
    }
   ],
   "source": [
    "data_dir = Path(\"../../data/txt\")\n",
    "all_txt = list(data_dir.rglob(\"*.txt\"))\n",
    "\n",
    "year_pat = re.compile(r\"(18|19)\\d{2}\")\n",
    "years = []\n",
    "\n",
    "for p in all_txt:\n",
    "    m = year_pat.search(p.name)\n",
    "    if m:\n",
    "        years.append(m.group(0))\n",
    "\n",
    "year_counts = Counter(years)\n",
    "print(f\"Total fichiers txt: {len(all_txt)}\")\n",
    "print(f\"Années détectées: {len(year_counts)}\")\n",
    "\n",
    "for y, c in sorted(year_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"{y}: {c}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choix et chargement de l'annee 1950"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers trouvés pour 1950: 4\n",
      "Taille du corpus 1950: 133,895 caractères\n",
      "\n",
      "Extrait:\n",
      " L'AVENIR DU LUXEMBOURG Samedi 15 avri j 350, \n",
      "MORHET \n",
      "Soirée dramatique \n",
      "1 Le cercle dramatique Sainte-Cécile \n",
      "de Morhet reprendra, ce dimanche 16 \n",
      "avril ^Quasimodo), sa brillante soirée \n",
      "qui a remporté un succès si remarqua-\n",
      "| bie le 10 mars dernier. \n",
      "i Rappelons ie programme : \n",
      "; 1) ouverture : « Brabançonne »,par \n",
      "• la Fantare ; 2) « La .bohème », chœur \n",
      "à 2 voix exécuté par JV^.es Renée Cara, \n",
      "j Josée Goffin, Anyse Hubermont et Hé-\n",
      "f lène Bellanger ; a) La comédie en deux \n",
      "actes de Marcell* \n"
     ]
    }
   ],
   "source": [
    "YEAR = \"1950\"\n",
    "pat = re.compile(rf\"{YEAR}\")\n",
    "\n",
    "files_year = [p for p in all_txt if pat.search(p.name)]\n",
    "print(f\"Fichiers trouvés pour {YEAR}: {len(files_year)}\")\n",
    "\n",
    "corpus_year = \"\"\n",
    "for path in files_year:\n",
    "    for enc in (\"utf-8\", \"latin-1\", \"cp1252\"):\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=enc, errors=\"ignore\") as f:\n",
    "                corpus_year += f.read() + \"\\n\"\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "print(f\"Taille du corpus {YEAR}: {len(corpus_year):,} caractères\")\n",
    "print(\"\\nExtrait:\\n\", corpus_year[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction de Keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'yake'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01myake\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'yake'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraire les mots clés d'un document avec Yake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/LIAAD/yake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantier l'extracteur de mots clés\n",
    "kw_extractor = yake.KeywordExtractor(lan=\"fr\", top=50)\n",
    "kw_extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lister les Fichiers\n",
    "data_path = \"../data/txt/\"\n",
    "files = [f for f in os.listdir(data_path) if f.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimer le nombre de fichiers identifiés\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Les dix premiers fichiers\n",
    "files[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choisir un fichier\n",
    "this_file = files[0]\n",
    "this_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Récupérer le texte du fichier\n",
    "text = open(os.path.join(data_path, this_file), 'r', encoding='utf-8').read()\n",
    "text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extraire les mots clés de ce texte\n",
    "keywords = kw_extractor.extract_keywords(text)\n",
    "keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ne garder que les bigrammes\n",
    "kept = []\n",
    "for kw, score in keywords:\n",
    "    words = kw.split()\n",
    "    if len(words) == 2:\n",
    "        kept.append(kw)\n",
    "kept"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire la même opération sur tous les documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in sorted(files)[:10]:\n",
    "    text = open(os.path.join(data_path, f), 'r', encoding=\"utf-8\").read()\n",
    "    keywords = kw_extractor.extract_keywords(text)\n",
    "    kept = []\n",
    "    for kw, score in keywords:\n",
    "        words = kw.split()\n",
    "        if len(words) == 2:\n",
    "            kept.append(kw)\n",
    "    print(f\"{f} mentions these keywords: {', '.join(kept)}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJET_TAC_1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
