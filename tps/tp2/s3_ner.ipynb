{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reconnaissance d'entités nommées avec SpaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparation et chargement du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichiers trouvés pour 1950: 4\n",
      "Taille du corpus 1950: 133,895 caractères\n",
      "\n",
      "Extrait:\n",
      " L'AVENIR DU LUXEMBOURG Samedi 15 avri j 350, \n",
      "MORHET \n",
      "Soirée dramatique \n",
      "1 Le cercle dramatique Sainte-Cécile \n",
      "de Morhet reprendra, ce dimanche 16 \n",
      "avril ^Quasimodo), sa brillante soirée \n",
      "qui a remporté un succès si remarqua-\n",
      "| bie le 10 mars dernier. \n",
      "i Rappelons ie programme : \n",
      "; 1) ouverture : « Brabançonne »,par \n",
      "• la Fantare ; 2) « La .bohème », chœur \n",
      "à 2 voix exécuté par JV^.es Renée Cara, \n",
      "j Josée Goffin, Anyse Hubermont et Hé-\n",
      "f lène Bellanger ; a) La comédie en deux \n",
      "actes de Marcell* \n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "\n",
    "data_dir = Path(\"../../data/txt\")\n",
    "\n",
    "all_txt = list(data_dir.glob(\"*.txt\"))\n",
    "\n",
    "YEAR = \"1950\"\n",
    "pat = re.compile(rf\"{YEAR}\")\n",
    "\n",
    "files_year = [p for p in all_txt if pat.search(p.name)]\n",
    "print(f\"Fichiers trouvés pour {YEAR}: {len(files_year)}\")\n",
    "\n",
    "corpus_year = \"\"\n",
    "for path in files_year:\n",
    "    for enc in (\"utf-8\", \"latin-1\", \"cp1252\"):\n",
    "        try:\n",
    "            with open(path, \"r\", encoding=enc, errors=\"ignore\") as f:\n",
    "                corpus_year += f.read() + \"\\n\"\n",
    "            break\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "print(f\"Taille du corpus {YEAR}: {len(corpus_year):,} caractères\")\n",
    "print(\"\\nExtrait:\\n\", corpus_year[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La documentation est accessible ici: https://spacy.io/api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fr-core-news-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/fr_core_news_sm-3.8.0/fr_core_news_sm-3.8.0-py3-none-any.whl (16.3 MB)\n",
      "     ---------------------------------------- 0.0/16.3 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 2.1/16.3 MB 10.7 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 4.5/16.3 MB 11.1 MB/s eta 0:00:02\n",
      "     ---------------- ----------------------- 6.8/16.3 MB 11.3 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 9.2/16.3 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 11.8/16.3 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 14.4/16.3 MB 11.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  16.3/16.3 MB 11.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 16.3/16.3 MB 10.9 MB/s  0:00:01\n",
      "Installing collected packages: fr-core-news-sm\n",
      "Successfully installed fr-core-news-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('fr_core_news_sm')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import spacy\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"fr_core_news_lg\")\n",
    "except OSError:\n",
    "    nlp = spacy.load(\"fr_core_news_sm\")\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analyse d'un petit extrait du corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AVENIR : ORG\n",
      "Samedi : PER\n",
      "Soirée : LOC\n",
      "Sainte-Cécile : LOC\n",
      "Morhet : PER\n",
      "Brabançonne : LOC\n",
      "JV^.es Renée Cara : PER\n",
      "j Josée Goffin : LOC\n",
      "Anyse Hubermont : PER\n",
      "lène Bellanger : PER\n",
      "Marcell : LOC\n",
      "Joignet : LOC\n",
      "Monastère : ORG\n",
      "Josée Goffin : PER\n",
      "Marie- : MISC\n",
      "Louise Flamant : PER\n",
      "Madeleine Ska : PER\n",
      "Renée \n",
      "Cara : PER\n",
      "Solange Noirot : PER\n",
      "Jeanine Grand- : PER\n",
      "Madeleine Van Mullem : PER\n",
      "La \n",
      "Vierge du Portail de : PER\n",
      "Philippe Gérard : PER\n",
      "Renée Lambert : PER\n",
      "Madeleine Ska : PER\n",
      "Renée Cara : PER\n",
      "Jeanine Grandjean : PER\n",
      "Louise Flamant : PER\n",
      "Marguerite Maquet : PER\n",
      "Solange Grandjean : PER\n",
      "M. Cartier-Bresson : PER\n",
      "E- : ORG\n",
      "Interorétée : PER\n",
      "Madeleine Ska : PER\n",
      "Jeanine Grandjean : PER\n",
      "Marguerite : PER\n",
      "Jeanne Bays : PER\n",
      "Solange Noirot : PER\n",
      "Van Mullem : PER\n",
      "Marie-Louise Fla­ : PER\n",
      "Josée Goffin : PER\n",
      "Solange Grand­ : PER\n",
      "Intermèdes : LOC\n",
      "tombola : LOC\n",
      "Vers l'Avenir : MISC\n",
      "Fan-\n",
      "lare : LOC\n",
      "La Fanfare : LOC\n",
      "M. Emile \n",
      "Binet : PER\n",
      "Arlon : LOC\n",
      "Le dimanche de Pâques : ORG\n"
     ]
    }
   ],
   "source": [
    "sample_text = corpus_year[:1500]\n",
    "doc = nlp(sample_text)\n",
    "\n",
    "#verification des entites detectees\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, \":\", ent.label_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('fr_core_news_md')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exemple sur un corpus de test fourni par SpaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imprimer le corpus de Spacy\n",
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isoler la première phrase\n",
    "sent = sentences[0]\n",
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Traiter la phrase avec Spacy\n",
    "doc = nlp(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appliquer le test sur toutes les phrases\n",
    "for sent in sentences:\n",
    "    doc = nlp(sent)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        entities.append(f\"{ent.text} ({ent.label_})\")\n",
    "    if entities:\n",
    "        print(f\"'{doc.text}' contient les entités suivantes : {', '.join(entities)}\")\n",
    "    else:\n",
    "        print(f\"'{doc.text}' ne contient aucune entité\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appliquer la reconnaissance d'entités nommées sur notre corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Charger le texte\n",
    "n=1000000\n",
    "text = open(\"../data/all.txt\", encoding='utf-8').read()[:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Traiter le texte\n",
    "\n",
    "doc = nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compter les entités\n",
    "people = defaultdict(int)\n",
    "for ent in doc.ents:\n",
    "    if ent.label_ == \"PER\" and len(ent.text) > 3:\n",
    "        people[ent.text] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trier et imprimer\n",
    "\n",
    "sorted_people = sorted(people.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "for person, freq in sorted_people[:50]:\n",
    "    print(f\"{person} apparait {freq} fois dans le corpus\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercice: essayez de lister les lieux (LOC) et les organisations (ORG) les plus mentionnées dans le corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PROJET_TAC_1_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
